# 🚇 Zookeeper 重要概念详解

---

## 1. 什么是 Zookeeper

ZooKeeper 是一个开源的**分布式协调服务**，它的设计目标是将那些复杂且容易出错的分布式一致性服务封装起来，构成一个高效可靠的**原语集**，并以一系列简单易用的接口提供给用户使用。

> 💡 所谓**分布式协调服务**就是**将各个分布式组件协调起来**，减少各个系统之间的耦合度、处理分布式事务、配置整个分布式系统等等
>
> 💡 **原语：** 操作系统或计算机网络用语范畴。是由若干条指令组成的，用于完成一定功能的一个过程。具有不可分割性，即原语的执行必须是连续的，在执行过程中不允许被中断。

**ZooKeeper 为我们提供了高可用、高性能、稳定的分布式数据一致性解决方案，通常被用于实现诸如数据发布/订阅、负载均衡、命名服务、分布式协调/通知、集群管理、Master 选举、分布式锁和分布式队列等功能。**

另外，**ZooKeeper 将数据保存在内存中，性能是非常棒的。 在“读”多于“写”的应用程序中尤其地高性能，因为“写”会导致所有的服务器间同步状态。（“读”多于“写”是协调服务的典型场景）。**

> 💡 关于“ZooKeeper”这个项目的名字，其实也有一段趣闻。
>
> 在立项初期，考虑到之前内部很多项目都是使用动物的名字来命名的（例如著名的 Pig 项目),雅虎的工程师希望给这个项目也取一个动物的名字。时任研究院的首席科学家 RaghuRamakrishnan 开玩笑地说：“在这样下去，我们这儿就变成动物园了！”此话一出，大家纷纷表示就叫动物园管理员吧一一一因为<u>各个以动物命名的分布式组件放在一起，雅虎的整个分布式系统看上去就像一个大型的动物园了，而 ZooKeeper 正好要用来进行分布式环境的协调一一于是，ZooKeeper 的名字也就由此诞生了</u>。

## 2. Zookeeper 特点

- **顺序一致性：** 从同一客户端发起的事务请求，最终将会严格地<u>按照顺序</u>被应用到 ZooKeeper 中去。
- **原子性：** 所有事务请求的处理结果在整个集群中所有机器上的应用情况是一致的，也就是说，<u>要么整个集群中所有的机器都成功应用了某一个事务，要么都没有应用</u>。
- **单一系统映像 ：** <u>无论客户端连到哪一个 ZooKeeper 服务器上，其看到的服务端数据模型都是一致的</u>。
- **可靠性：** <u>一旦一次更改请求被应用，更改的结果就会被持久化，直到被下一次更改覆盖</u>。

## 3. Zookeeper 重要概念解读

### ① 数据模型 Data Model

ZooKeeper 数据模型采用**层次化的多叉树形结构（类似于 Linux 文件系统）**，**每个节点上都可以存储数据**，这些数据可以是数字、字符串或者是二级制序列。

并且，每个节点还可以拥有 N 个子节点，最上层是根节点以“`/`”来代表。每个数据节点在 ZooKeeper 中被称为 **节点 znode**，它是 ZooKeeper 中数据的最小单元。**每个 znode 都有一个唯一的路径标识**。开发人员可以向节点中写入数据，也可以在节点下面创建子节点，这些操作我们后面都会介绍到。

![](https://gitee.com/veal98/images/raw/master/img/20201129150633.png)

🚨 强调一句：**ZooKeeper 主要是用来协调服务的，而不是用来存储业务数据的，所以不要放比较大的数据在 znode 上，ZooKeeper 给出的上限是每个结点的数据大小最大是 1M。**

### ② 数据节点 znode

每个数据节点在 ZooKeeper 中被称为 **znode**，它是 ZooKeeper 中数据的最小单元。你要存放的数据就放在上面

#### Ⅰ znode 4 种类型

💧 我们通常是将 znode 分为 4 大类：

- **持久（`PERSISTENT`）节点** ：一旦创建就一直存在即使 ZooKeeper 集群宕机，直到将其删除。
- **临时（`EPHEMERAL`）节点** ：临时节点的生命周期是与 **客户端会话（session）** 绑定的，**会话消失则节点消失** 。并且，**临时节点只能做叶子节点** ，不能创建子节点。
- **持久顺序（`PERSISTENT_SEQUENTIAL`）节点** ：除了具有持久（PERSISTENT）节点的特性之外， 子节点的名称还具有顺序性。比如 `/node1/app0000000001` 、`/node1/app0000000002` 。
- **临时顺序（`EPHEMERAL_SEQUENTIAL`）节点** ：除了具备临时（EPHEMERAL）节点的特性之外，子节点的名称还具有顺序性。

#### Ⅱ znode 数据结构

💧 每个 znode 由 2 部分组成：

- **stat** ：节点的**状态信息**

  通过 `get` 命令来获取 根目录下的 dubbo 节点的内容：

  ```shell
  [zk: 127.0.0.1:2181(CONNECTED) 6] get /dubbo
  # 该数据节点关联的数据内容为空
  null
  ```

- **data** ：节点存放的**数据的具体内容**

  节点状态中包含了很多节点的属性比如 `czxid` 、`mzxid` 等等，在 `zookeeper` 中是使用 `Stat` 这个类来维护的。下面列举一些属性解释：

  - `czxid`：`Created ZXID`，该数据节点被 **创建** 时的事务ID。
  - `mzxid`：`Modified ZXID`，节点 **最后一次被更新时** 的事务ID。
  - `ctime`：`Created Time`，该节点被创建的时间。
  - `mtime`： `Modified Time`，该节点最后一次被修改的时间。
  - `dataversion`：节点的版本号。
  - `cversion`：**子节点** 的版本号。
  - `aclVersion `：节点的 `ACL` 版本号。
  - `ephemeralOwner`：创建该节点的会话的 `sessionID` ，如果该节点为持久节点，该值为0。
  - `dataLength`：节点数据内容的长度。
  - `numChildre`：该节点的子节点个数，如果为临时节点为0。
  - `pzxid`：该节点子节点列表最后一次被修改时的事务ID，注意是子节点的 **列表** ，不是内容。

  通过 `stat` 命令来获取节点的状态：

  ```shell
  [zk: 127.0.0.1:2181(CONNECTED) 6] stat /dubbo
  # 下面是该数据节点的一些状态信息，其实就是 Stat 对象的格式化输出
  cZxid = 0x2
  ctime = Tue Nov 27 11:05:34 CST 2018
  mZxid = 0x2
  mtime = Tue Nov 27 11:05:34 CST 2018
  pZxid = 0x3
  cversion = 1
  dataVersion = 0
  aclVersion = 0
  ephemeralOwner = 0x0
  dataLength = 0
  numChildren = 1
  ```

### ③ 权限控制 ACL

ZooKeeper 采用 `ACL（Access Control Lists）访问控制列表` 策略来进行权限控制，类似于 UNIX 文件系统的权限控制。

对于 znode 操作的权限，ZooKeeper 提供了以下 5 种：

- **CREATE** : 能创建子节点
- **READ** ：能获取节点数据和列出其子节点
- **WRITE** : 能设置/更新节点数据
- **DELETE** : 能删除子节点
- **ADMIN** : 能设置节点 ACL 的权限

其中尤其需要注意的是，**CREATE** 和 **DELETE** 这两种权限都是针对 **子节点** 的权限控制。

### ④ 事件监听器 Watcher

`Watcher` 为事件监听器，该机制是 ZooKeeper 实现分布式协调服务的重要特性，很多功能都依赖于它，它有点<u>类似于订阅的方式</u>，即客户端向服务端 **注册** 指定的 `watcher` ，当服务端符合了 `watcher` 的某些事件或要求则会 **向客户端发送事件通知** ，客户端收到通知后找到自己定义的 `Watcher` 然后 **执行相应的回调方法** 。

![](https://gitee.com/veal98/images/raw/master/img/20201129152800.png)

### ⑤ 会话 Session

Session 可以看作是 ZooKeeper 服务器与客户端的之间的一个 **TCP 长连接**，通过这个连接，客户端能够通过心跳检测与服务器保持有效的会话，也能够向 ZooKeeper 服务器发送请求并接受响应，同时还能够通过该连接接收来自服务器的 Watcher 事件通知。

Session 有一个属性叫做：`sessionTimeout` ，`sessionTimeout` 代表会话的超时时间。当由于服务器压力太大、网络故障或是客户端主动断开连接等各种原因导致客户端连接断开时，只要在 `sessionTimeout` 规定的时间内能够重新连接上集群中任意一台服务器，那么之前创建的会话仍然有效。

另外，**在为客户端创建会话之前，服务端首先会为每个客户端都分配一个全局唯一的 `sessionID`**。由于  `sessionID` 是 ZooKeeper 会话的一个重要标识，许多与会话相关的运行机制都是基于这个 `sessionID` 的，因此，无论是哪台服务器为客户端分配的 `sessionID`，都务必保证全局唯一。

## 4. Zookeeper 架构

为了保证高可用，最好是以**集群**形态来部署 ZooKeeper，这样只要集群中大部分机器是可用的（能够容忍一定的机器故障），那么 ZooKeeper 本身仍然是可用的。通常 3 台服务器就可以构成一个 ZooKeeper 集群了。ZooKeeper 官方提供的架构图就是一个 ZooKeeper 集群整体对外提供服务。

![](https://gitee.com/veal98/images/raw/master/img/20201129153452.png)

上图中每一个 Server 代表一个安装 ZooKeeper 服务的服务器。组成 ZooKeeper 服务的服务器都会在内存中维护当前的服务器状态，并且每台服务器之间都互相保持着通信。集群间通过 `ZAB 协议（ZooKeeper Atomic Broadcast）` 来保持数据的一致性。

## 5. ZAB 协议

💡 作为一个优秀高效且可靠的分布式协调框架，`ZooKeeper` 在**解决分布式数据一致性问题**时并没有直接使用 `Paxos` 算法 ，而是专门定制了一致性协议叫做 `ZAB(ZooKeeper Automic Broadcast)` **原子广播协议**，该协议能够很好地支持 **崩溃恢复** 。

### ① 三种角色

**`ZAB` 协议 没有选择传统的 Master/Slave 主从集群模式，而是引入了 `Leader 领导者`、`Follower 跟随者 `和 `Observer 观察者` 三种角色**：

> 💡 **最典型的集群模式：Master/Slave 模式（主从模式）**。在这种模式中，通常 Master 服务器作为主服务器提供写服务，其他的 Slave 服务器从服务器通过异步复制的方式获取 Master 服务器最新的数据提供读服务。

![](https://gitee.com/veal98/images/raw/master/img/20201129153922.png)

- `Leader` ：集群中 **唯一的写请求处理者** ，能够发起投票（投票也是为了进行写请求）。
- `Follower`：能够接收客户端的请求，如果是读请求则可以自己处理，**如果是写请求则要转发给 `Leader`** 。在选举过程中会参与投票，**有选举权和被选举权** 。
- `Observer` ：就是**没有选举权和被选举权的 `Follower`** 。为客户端提供读服务器，如果是写服务则转发给 Leader。不参与选举过程中的投票。**在不影响写性能的情况下提升集群的读性能**。此角色于 ZooKeeper 3.3 系列新增的角色。

### ② 领导选举算法 FastLeaderElection

💧 **当 Leader 服务器出现网络中断、崩溃退出与重启等异常情况时，就会进入 Leader 选举过程，这个过程会选举产生新的 Leader 服务器**。这个过程大致是这样的（下文会详解）：

- **Leader election（选举阶段）**：节点在一开始都处于选举阶段，<u>只要有一个节点得到超半数节点的票数，它就可以当选准 leader</u>。

- **Discovery（发现阶段）** ：在这个阶段，followers 跟准 leader 进行通信，同步 followers 最近接收的事务提议。

- **Synchronization（同步阶段）** :同步阶段主要是利用 leader 前一阶段获得的最新提议历史，同步集群中所有的副本。<u>同步完成之后 准 leader 才会成为真正的 leader</u>。

- **Broadcast（广播阶段）** : <u>到了这个阶段，ZooKeeper 集群才能正式对外提供事务服务</u>，并且 leader 可以进行消息广播。同时如果有新的节点加入，还需要对新节点进行同步。

可通过 `electionAlg` 配置项设置 ZooKeeper 用于领导选举的算法。

到3.4.10版本为止，可选项有：

- 0 基于UDP的 `LeaderElection`
- 1 基于UDP的 `FastLeaderElection`
- 2 基于UDP和认证的 `FastLeaderElection`
- 3 基于TCP的 `FastLeaderElection`

在3.4.10版本中，默认值为 3，也即基于TCP的 `FastLeaderElection`。**另外三种算法已经被弃用**，并且有计划在之后的版本中将它们彻底删除而不再支持。

下面详细解释该算法：👇

#### Ⅰ myid

`myid`：**每个 ZooKeeper 服务器，都需要在数据文件夹下创建一个名为 `myid` 的文件，该文件包含整个 ZooKeeper 集群唯一的 ID（整数）**。

例如，某 ZooKeeper 集群包含三台服务器，`hostname `分别为`zoo1`、`zoo2` 和 `zoo3`，其 `myid` 分别为1、2 和 3，则在配置文件中其 ID 与 `hostname` 必须一一对应，如下所示。在该配置文件中，`server.` 后面的数据即为 `myid`

- server.1=zoo1:2888:3888
- server.2=zoo2:2888:3888
- server.3=zoo3:2888:3888

#### Ⅱ zxid

`zxid`：用于**标识一次更新操作的提议的 ID**。**全局单调递增** ，它是一个64位long型，其中高32位表示年代（`epoch`），低32位表示事务 id。年代是会根据 `Leader` 的变化而变化的，当一个 `Leader` 挂了，新的 `Leader` 上位的时候，年代就变了。而低32位可以简单理解为递增的事务 id。

定义这个的原因是为了顺序性，<u>每个提议在 `Leader` 中生成后需要 **通过其 `ZXID` 来进行排序** ，才能得到处理</u>。

#### Ⅲ 服务器状态

- **LOOKING** ：寻找 Leader。该状态下的服务器认为当前集群中没有Leader，会发起Leader选举。
- **LEADING** ：Leader 状态，对应的节点为 Leader。
- **FOLLOWING** ：Follower 状态，对应的节点为 Follower。
- **OBSERVING** ：Observer 状态，对应节点为 Observer，该节点不参与 Leader 选举。

#### Ⅳ 选票数据结构

每个服务器在进行领导选举时，会发送如下关键信息：

- **logicClock** 每个服务器会维护一个自增的整数，名为 logicClock，它<u>表示这是该服务器发起的第多少轮投票</u>
- **state** 当前服务器的状态
- **self_id** 当前服务器的 `myid`
- **self_zxid** 当前服务器上所保存的数据的最大 `zxid`
- **vote_id** 被推举的服务器的 `myid`
- **vote_zxid** 被推举的服务器上所保存的数据的最大 `zxid`

#### Ⅴ 投票流程

**自增选举轮次 `logicClock` **：

ZooKeeper 规定所有有效的投票都必须在同一轮次中。每个服务器在开始新一轮投票时，会先对自己维护的`logicClock` 进行自增操作。

**初始化选票**：

<u>每个服务器在广播自己的选票前，会将自己的投票箱清空</u>。该投票箱记录了所收到的选票。

例：服务器 2 投票给服务器 3，服务器 3 投票给服务器 1，则服务器 1 的投票箱为 (2, 3), (3, 1), (1, 1)。票箱中只会记录每一投票者的最后一票，如投票者更新自己的选票，则其它服务器收到该新选票后会在自己票箱中更新该服务器的选票。

**发送初始化选票**：

<u>每个服务器最开始都是通过广播把票投给自己</u>。

> 💬 举个例子：
>
> <img src="https://gitee.com/veal98/images/raw/master/img/20201129212625.png" style="zoom: 40%;" />
>
> 在上图中，`(1, 1, 0)` 第一位数代表投出该选票的服务器的 `logicClock`，第二位数代表被推荐的服务器的 `myid`，第三位代表被推荐的服务器的最大的 `zxid`。<u>由于该步骤中所有选票都投给自己，所以第二位的 `myid` 即是自己的 `myid`，第三位的 `zxid` 即是自己的 `zxid`</u>。
>
> 此时各自的票箱中只有自己投给自己的一票。

**接收外部投票**：

<u>服务器会尝试从其它服务器获取投票，并记入自己的投票箱内</u>。如果无法获取任何外部投票，则会确认自己是否与集群中其它服务器保持着有效连接。如果是，则再次发送自己的投票；如果否，则马上与之建立连接。

**判断选举轮次**：

收到外部投票后，首先会根据投票信息中所包含的 `logicClock` 来进行不同处理：

- 外部投票的 `logicClock` 大于自己的 `logicClock`。说明该服务器的选举轮次落后于其它服务器的选举轮次，立即清空自己的投票箱并将自己的 `logicClock` 更新为收到的 `logicClock`，然后再对比自己之前的投票与收到的投票以确定是否需要变更自己的投票，最终再次将自己的投票广播出去。
- 外部投票的 `logicClock` 小于自己的 `logicClock`。当前服务器直接忽略该投票，继续处理下一个投票。
- 外部投票的 `logickClock` 与自己的相等。进行选票 PK

**选票 PK**：

选票 PK 是基于 `(self_id, self_zxid)` 与 `(vote_id, vote_zxid)` 的对比：

- 先对比二者的 `vote_zxid`，若外部投票的 `vote_zxid` 比较大，则将自己的票中的 `vote_zxid` 与 `vote_myid` 更新为收到的票中的 `vote_zxid` 与 `vote_myid` 并广播出去，另外将收到的票及自己更新后的票放入自己的票箱。如果票箱内已存在 `(self_myid, self_zxid)` 相同的选票，则直接覆盖
- 若二者 `vote_zxid` 一致，则比较二者的 `vote_myid`，若外部投票的 `vote_myid` 比较大，则将自己的票中的 `vote_myid` 更新为收到的票中的 `vote_myid` 并广播出去，另外将收到的票及自己更新后的票放入自己的票箱

> 💬 接上图：
>
> <img src="https://gitee.com/veal98/images/raw/master/img/20201129212802.png" style="zoom:40%;" />
>
> 服务器 1 收到服务器 2 的选票（1, 2, 0）和服务器 3 的选票（1, 3, 0）后，由于所有的 `logicClock` 都相等，所有的 `zxid` 都相等，因此根据 `myid` 判断应该将自己的选票按照服务器 3 的选票更新为（1, 3, 0），并将自己的票箱全部清空，再将服务器 3 的选票与自己的选票存入自己的票箱，接着将自己更新后的选票广播出去。此时服务器1票箱内的选票为(1, 3)，(3, 3)。
>
> 同理，服务器 2 收到服务器3的选票后也将自己的选票更新为（1, 3, 0）并存入票箱然后广播。此时服务器 2 票箱内的选票为 (2, 3)，(3, ,3)。
>
> 服务器 3 根据上述规则，无须更新选票，自身的票箱内选票仍为（3, 3）。
>
> 服务器 1 与服务器 2 更新后的选票广播出去后，由于三个服务器最新选票都相同，最后三者的票箱内都包含三张投给服务器 3 的选票。

**统计选票**：

<u>如果已经确定有过半服务器认可了自己的投票（可能是更新后的投票），则终止投票</u>。否则继续接收其它服务器的投票。

**更新服务器状态**：

<u>投票终止后，服务器开始更新自身状态。若过半的票投给了自己，则将自己的服务器状态更新为 `LEADING`，否则将自己的状态更新为 `FOLLOWING`</u>。

> 💬 接上图：
>
> <img src="https://gitee.com/veal98/images/raw/master/img/20201129213154.png" style="zoom:40%;" />
>
> 根据上述选票，三个服务器一致认为此时服务器 3 应该是Leader。因此服务器 1 和 2 都进入 `FOLLOWING` 状态，而服务器3进入 `LEADING` 状态。之后 Leader 发起并维护与 Follower 间的心跳。

### ③ 两种模式

在 `ZAB` 协议中对 `zkServer`(即上面我们说的三个角色的总称) 还有两种模式的定义，分别是 **消息广播** 和 **崩溃恢复** 

#### Ⅰ 消息广播模式

**消息广播模式**：说白了就是 `ZAB` 协议是如何处理写请求的，上面我们不是说只有 `Leader` 能处理写请求嘛？那么我们的 `Follower` 和 `Observer` 是不是也需要 **同步更新数据** 呢？总不能数据只在 `Leader` 中更新了，其他角色都没有得到更新吧 ？

第一步肯定需要 `Leader` 将写请求 **广播** 出去，让 `Leader` 问问 `Followers` 是否同意更新，<u>如果超过半数以上的同意那么就进行 `Follower` 和 `Observer` 的更新</u>（和 `Paxos` 一样）

![](https://gitee.com/veal98/images/raw/master/img/20201129154501.png)

上图中的 **Queue 队列是为了保证顺序性**：比如我现在有一个写请求 A，此时 `Leader` 将请求 A 广播出去，因为只需要半数同意就行，所以可能这个时候有一个 `Follower` F1 因为网络原因没有收到，而 `Leader` 又广播了一个请求 B，因为网络原因，F1 先收到了请求 B 然后才收到了请求 A，这个时候请求处理的顺序不同就会导致数据的不同，从而 **产生数据不一致问题**

所以在 `Leader` 这端，它为每个其他的 `zkServer` 准备了一个 **队列** ，采用先进先出的方式发送消息。由于协议是 **通过 `TCP` 来进行网络通信**的，保证了消息的发送顺序性，接受顺序性也得到了保证

#### Ⅱ 崩溃恢复模式

🔸 **崩溃恢复模式**：<u>当整个服务框架在启动过程中，或是当 Leader 服务器出现网络中断、崩溃退出与重启等异常情况时，ZAB 协议就会进入恢复模式并选举产生新的 Leader 服务器。当选举产生了新的 Leader 服务器，同时集群中已经有过半的机器与该 Leader 服务器完成了状态同步之后，ZAB 协议就会退出恢复模式</u>。其中，**所谓的状态同步是指数据同步，用来保证集群中存在过半的机器能够和 Leader 服务器的数据状态保持一致**。

### ④ ZooKeeper 集群最好是奇数台
ZooKeeper 集群在宕掉几个 ZooKeeper 服务器之后，**如果剩下的 ZooKeeper 服务器个数大于宕掉的个数的话，整个 ZooKeeper 才依然可用**。

假如我们的集群中有 n 台 ZooKeeper 服务器，那么也就是剩下的服务数必须大于 `n/2`。先说一下结论，`2n` 和 `2n-1` 的容忍度是一样的，都是 `n-1`。 比如假如我们有 3 台，那么最大允许宕掉 1 台 ZooKeeper 服务器，如果我们有 4 台的的时候也同样只允许宕掉 1 台。 假如我们有 5 台，那么最大允许宕掉 2 台 ZooKeeper 服务器，如果我们有 6 台的的时候也同样只允许宕掉 2 台。

综上，**何必增加那一个不必要的 ZooKeeper 呢？**

## 6. ZooKeeper 典型应用场景

### ① Master 选举

针对Master选举的需求，通常情况下，我们可以选择常见的**关系型数据库**中的**主键特性**来实现：希望成为Master的机器都向数据库中插入一条**相同主键ID**的记录，数据库会帮我们进行**主键冲突检查**，也就是说，**只有一台**机器能插入成功——那么，我们就认为向数据库中**成功插入**数据的客户端机器**成为Master**。

<u>依靠关系型数据库的主键特性确实能够很好地保证在集群中选举出唯一的一个Master。但是，👍 **如果当前选举出的Master挂了，那么该如何处理？谁来告诉我Master挂了呢？显然，关系型数据库无法通知我们这个事件。但是，ZooKeeper可以做到！**</u>

因为 `Zookeeper` 的强一致性，能够很好地在保证 **在高并发的情况下保证节点创建的全局唯一性** (也就是说，如果同时有多个客户端请求创建**同一个**节点，那么最终一定**只有一个**客户端请求能够创建成功。)。利用这个特性，我们可以 **让多个客户端创建一个指定的节点** ，创建成功的就是 `master`。

成功创建该节点的客户端所在的机器就成为了 Master。同时，**其他没有成功创建该节点的客户端，都会在该节点上注册一个子节点变更的 `Watcher`**，用于监控当前 Master 机器是否存活，一旦发现当前的Master挂了，那么其他客户端将会**重新进行Master选举**。

![](https://gitee.com/veal98/images/raw/master/img/20201129215431.png)

### ② 分布式锁

分布式锁是控制**分布式系统**之间**同步访问共享资源**的一种方式。分布式锁的实现方式有很多种，比如 `Redis` 、数据库 、`zookeeper` 等。

上面我们已经提到过了 **zk 在高并发的情况下保证节点创建的全局唯一性**，这个特性同样可用于实现**排他锁**，又因为能在分布式的情况下，所以能实现**分布式锁**。分布式锁又分为**排他锁**和**共享锁**两种。下面我们来详细讲解如何利用 Zookeeper 实现排他锁和共享锁 👇

#### Ⅰ 获取锁

ZooKeeper上的**一个 ZNode 可以表示一个锁**。例如 `/exclusive_lock/lock`节点就可以被定义为一个锁。

首先是获取锁，因为创建节点的唯一性，我们可以让**多个客户端同时创建一个临时节点（所有客户端都去 `/exclusive_lock` 节点下创建临时子节点 `/exclusive_lock/lock`）**，**创建成功的就说明获取到了锁** 。所有没有获取到锁的客户端就需要到 `/exclusive_lock` 节点上注册一个子节点变更的 `Watcher` 监听，如果这个互斥锁被释放了（可能获取锁的客户端宕机了，或者那个客户端主动释放了锁）可以调用回调函数重新获得锁。

#### Ⅱ 释放锁

因为 `/exclusive_lock/lock` 是一个**临时节点**，因此在以下两种情况下，都有可能释放锁：

- 当前获得锁的客户端机器发生**宕机**或**重启**，那么该临时节点就会**被删除，释放锁**。
- 正常执行完业务逻辑后，客户端就会**主动**将自己创建的临时节点**删除，释放锁**。

无论在什么情况下移除了lock节点，ZooKeeper都会**通知**所有在 `/exclusive_lock` 节点上注册了节点变更 `Watcher` 监听的客户端。这些客户端在接收到通知后，再次**重新发起**分布式锁获取，即重复『获取锁』过程。

> `zk` 中不需要向 `redis` 那样考虑锁得不到释放的问题了，因为当客户端挂了，节点也挂了，锁也释放了。

#### Ⅲ 共享锁 / 排他锁

> 💡 **排他锁（Exclusive Locks，简称X锁）**，又称为**写锁**或**独占锁**。如果事务T1对数据对象O1加上了排他锁，那么在整个加锁期间，只允许事务 T1 对 O1 进行**读取和更新**操作，其他任何事务都不能在对这个数据对象进行任何类型的操作（不能再对该对象加锁），直到T1释放了排他锁。
>
> 💡 **共享锁（Shared Locks，简称 S 锁）**，又称为**读锁**。如果事务T1对数据对象O1加上了共享锁，那么T1只能对O1进行**读操作**，其他事务也能**同时对O1加共享锁**（不能是排他锁），直到O1上的所有共享锁都释放后O1才能被加排他锁。

我们**规定所有创建节点必须有序**，当你是读请求（要获取共享锁）的话，如果 **没有比自己更小的节点，或比自己小的节点都是读请求** ，则可以获取到读锁，然后就可以开始读了。**若比自己小的节点中有写请求** ，则当前客户端无法获取到读锁，只能等待前面的写请求完成。

如果你是写请求（获取排他锁），若 **没有比自己更小的节点** ，则表示当前客户端可以直接获取到写锁，对数据进行修改。若发现 **有比自己更小的节点，无论是读操作还是写操作，当前客户端都无法获取到写锁** ，等待所有前面的操作完成。

这就很好地同时实现了共享锁和排他锁

### ③ 命名服务

如何给一个对象设置ID，大家可能都会想到 `UUID`，但是 `UUID` 最大的问题就在于它太长了。那么在条件允许的情况下，我们能不能使用 `zookeeper` 来实现呢？

`zookeeper` 是通过 **树形结构** 来存储数据节点的，每个节点的 **全路径** 它必定是唯一的，我们可以使用节点的全路径作为命名方式。而且更重要的是，路径是我们可以自己定义的，这对于我们对有些有语意的对象的 ID 设置可以更加便于理解。

### ④ 集群管理和注册中心

`zookeeper` 天然支持的 `watcher` 和 临时节点能很好的实现数据发布/订阅（集群管理）。我们可以为每条机器创建临时节点，并监控其父节点，如果子节点列表有变动，那么我们可以使用在其父节点绑定的 `watcher` 进行状态监控和回调。

![](https://gitee.com/veal98/images/raw/master/img/20201129220735.png)

Zookeeper 作为注册中心就是让 **服务提供者** 在 `zookeeper` 中创建一个临时节点并且将自己的 `ip、port、调用方式` 写入节点，当 **服务消费者** 需要进行调用的时候会 **通过注册中心找到相应的服务的地址列表(IP端口什么的)** ，并缓存到本地(方便以后调用)，当消费者调用服务时，不会再去请求注册中心，而是直接通过负载均衡算法从地址列表中取一个服务提供者的服务器调用服务。

![](https://gitee.com/veal98/images/raw/master/img/20201129220840.png)

当服务提供者的某台服务器宕机或下线时，相应的地址会从服务提供者地址列表中移除。同时，注册中心会将新的服务地址列表发送给服务消费者的机器并缓存在消费者本机。

## 📚 References

- [Github - Advanced Java](https://doocs.gitee.io/advanced-java/#/./docs/distributed-system/distributed-system-interview)
- [Github - CS-Notes](http://cyc2018.gitee.io/cs-notes/#/notes/分布式?id=一、分布式锁)
- [Github - JavaGuide](https://snailclimb.gitee.io/javaguide/#/docs/system-design/distributed-system/分布式?id=二-分布式事务)
- [郭俊 - 实例详解ZooKeeper ZAB协议、分布式锁与领导选举](https://dbaplus.cn/news-141-1875-1.html)
- [ZooKeeper典型应用场景](https://www.cnblogs.com/tongxupeng/p/10424246.html)