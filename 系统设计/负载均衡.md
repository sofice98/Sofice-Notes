# 集群、分布式、负载均衡的区别

- **集群（cluster）**：一组计算机/服务器，它们作为一个整体向用户提供一组网络资源，这些单个的计算机系统就是集群的**节点（node）**。

  简单来说就是：将几台服务器集中在一起，实现同一业务。集群是个物理形态。

  <img src="http://mdimg.sofice.top/202112301653308.png" style="zoom: 60%;" />

- **分布式**：所谓分布式业务系统，就是把原来一个大块系统，拆分成多个独立的子系统，独立的子系统/模块部署在独立的服务器（集群）上，从物理上分离模块之间的耦合关系，进一步降低耦合性提高复用性。这些子系统/模块以消息传递及依赖调用的方式聚合成一个完整的系统。

  简单来说就是：将一个业务分拆多个子业务，部署在不同的服务器上。分布式是个工作方式。

  <img src="http://mdimg.sofice.top/202112301654297.png" style="zoom:67%;" />

- **负载均衡**：在业务量和数据量较高的情况下，单台服务器无法承担所有的负载压力，通过负载均衡手段，将流量和数据分摊到一个集群组成的多台服务器上，以提高整体的负载处理能力。

  <img src="http://mdimg.sofice.top/202112301655982.png" style="zoom:50%;" />

**集群与分布式**

- 只要是一堆机器，就可以叫集群，他们是不是一起协作着干活，这个谁也不知道；
- 一个程序或系统，只要运行在不同的机器上，就可以叫分布式

集群一般是物理集中、统一管理的，而分布式系统则不强调这一点。

所以，**集群可能运行着一个或多个分布式系统，也可能根本没有运行分布式系统；分布式系统可能运行在一个集群上，也可能运行在不属于一个集群的多台（2台也算多台）机器上**。



**举例说明**

你被领导要求完成一份文档的编写工作，我们把它看做是计算机要进行处理的业务。

- 这个文档由多个人分解成多个子文档，每个人完成一部分，最后拼装成完整的文档，这就是**集群**的工作

- 如果这个文档放在一个机器上，多人同时访问会导致响应速度变慢，这时候网管多放了几台机器，每个机器上都有这个文档，访问者会自动被分配到访问较少的服务器上处理该文档，这就叫**负载均衡**。

- 如果这个文档编写工作需要编写的不止一份文档，而是多个文档，这时由多个人分别处理其中的一部分（而且每次都是同一人处理同一个部分），这就叫**分布式**。



# 负载均衡

负载均衡（Load Balance）建立在现有网络结构之上，提供了一种廉价、有效、透明的方法来扩展网络设备和服务器的带宽，增加了吞吐量，加强了网络数据处理能力，并提高了网络的灵活性和可用性。

<img src="http://mdimg.sofice.top/202112301655982.png" style="zoom: 33%;" />

负载均衡是分布式系统架构设计中必须考虑的因素之一。**一般通过负载均衡，冗余同一个服务实例的方式，解决分布式系统的大流量、高并发和高可用的问题。**

负载均衡==核心==关键在于**是否分配均匀**。

负载均衡服务器运行过程包含两个部分：

- 根据负载均衡算法 和 Web 服务器列表得到集群中一台 Web 服务器的地址
- 将请求数据发送到该地址对应的 Web 服务器上。



## 四层负载均衡 & 七层负载均衡

项目中常用的负载均衡有四层负载均衡和七层负载均衡：

- 四层负载均衡：基于 **IP 和端口**的方式实现**网络**的负载均衡，具体实现为对外提供一个虚拟 IP 和端口接收所有用户的请求，然后根据负载均衡配置和负载均衡策略将请求发送给真实的服务器。

  常用软硬件：F5，LVS，Nginx

- 七层负载均衡：基于 **URL 等资源**来实现**应用层基于内容**的负载均衡，具体实现为通过虚拟的URL或主机名接收所有用户的请求，然后将请求发送给真实的服务器。

  常用软硬件：HAProxy，Apache，Nginx

四层负载均衡和七层负载均衡的差别：

四层负载均衡只能针对IP地址和端口上的数据做统一的分发，而七层负载均衡能根据消息的内容做更加详细的有针对性的负载均衡。我们通常使用LVS等技术实现基于Socket的四层负载均衡，使用Nginx 等技术实现基于内容分发的七层负载均衡，比如将以`／user/***`开头的 URL 请求负载到单点登录服务器，而将以`／business/***`开头的URL 请求负载到具体的业务服务器。

<img src="http://mdimg.sofice.top/202201231607998.png" alt="image-20220123160726603" style="zoom: 20%;" />



# 负载均衡算法

1. **轮询（Round Robin）**

   **轮询算法把每个请求轮流发送到每个服务器上。**

   该算法比较适合每个服务器的性能差不多的场景，如果有性能存在差异的情况下，那么性能较差的服务器可能无法承担过大的负载。

2. **加权轮询（Weighted Round Robin）**

   加权轮询是在轮询的基础上，根据服务器的性能差异，**为服务器赋予一定的权值，性能高的服务器分配更高的权值**。

3. **随机算法（Random）**

   把请求随机发送到服务器上。

   和轮询算法类似，该算法比较适合服务器性能差不多的场景。

4. **加权随机（Weighted Random）**

   类似加权轮询的随机算法

5. **响应速度（Response Time）**

   转发到响应速度最快的服务器上。通过定时探测获取响应速度。有效避免单点负载过高，但有一定误差。

6. **最少连接数（Least Connection）**

   转发给当前最少连接数的服务器上，负载均衡器内部记录连接数。

   **由于每个请求的连接时间不一样**，使用轮询或者加权轮询算法的话，可能会让一台服务器当前连接数过大，而另一台服务器的连接过小，造成负载不均衡。

   例如下图中，(1, 3, 5) 请求会被发送到服务器 1，但是 (1, 3) 很快就断开连接，此时只有 (5) 请求连接服务器 1；(2, 4, 6) 请求被发送到服务器 2，只有 (2) 的连接断开，此时 (6, 4) 请求连接服务器 2。该系统继续运行时，服务器 2 会承担过大的负载。

   <img src="http://mdimg.sofice.top/202112301705202.png" style="zoom:50%;" />

   使用此算法后，例如下图中，服务器 1 当前连接数最小，那么新到来的请求 6 就会被发送到服务器 1 上。

   <img src="http://mdimg.sofice.top/202112301705206.png" style="zoom:50%;" />

7. **加权最少连接（Weighted Least Connection）**

   在最少连接的基础上，根据服务器的性能为每台服务器分配权重，再根据权重计算出每台服务器能处理的连接数。

8. **处理能力**

   分配负荷最轻的服务器。考虑了处理能力，网络状况等，更加精确，尤其适合七层负载均衡。

9. **DNS 响应（Flash DNS）**

   不同机房的负载均衡设备均解析服务器IP返回给客户端，客户端选择收到的第一个解析。

10. **散列算法**

    通过**一致性散列算法**和**虚拟节点技术**将相同参数的请求发送到同一台服务器。某一台宕机后，通过虚拟节点技术平摊到其他服务器。

11. **IP 地址散列**

    源地址哈希通过对客户端 IP 计算哈希值之后，再对服务器数量取模得到目标服务器的序号。

    可以保证同一 IP 的客户端的请求会转发到同一台服务器上，用来实现**会话粘滞**

12. **URL 散列**

    将相同 URL 请求转发给同一台服务器，适用于**动静分离**。



# 负载均衡的实现技术

实现负载均衡，其实就是实现 HTTP 请求的分发/转发（将请求数据发送到该地址对应的 Web 服务器上），基础技术不外乎以下几种 👇

## ① HTTP 重定向负载均衡

利用 HTTP 重定向协议实现负载均衡

HTTP 重定向负载均衡服务器使用某种负载均衡算法计算得到服务器的 IP 地址之后，将该地址写入 HTTP 重定向报文中，状态码为 302。客户端收到重定向报文之后，需要重新向服务器发起请求。

<img src="http://mdimg.sofice.top/202112301708529.png" style="zoom:50%;" />

缺点：

- 需要两次请求，因此访问延迟比较高；
- HTTP 负载均衡器处理能力有限，会限制集群的规模。

该负载均衡转发的缺点比较明显，**实际场景中很少使用它**。

## ② DNS 域名解析负载均衡

在 DNS 解析域名的同时使用负载均衡算法计算服务器 IP 地址。

<img src="http://mdimg.sofice.top/202112301710613.png" style="zoom:50%;" />

优点：

- DNS 能够根据地理位置进行域名解析，返回离用户最近的服务器 IP 地址。

缺点：

- 由于 DNS 具有多级结构，每一级的域名记录都可能被缓存，当下线一台服务器需要修改 DNS 记录时，需要过很长一段时间才能生效。

**大型网站基本使用了 DNS 做为第一级负载均衡手段，然后在内部使用其它方式做第二级负载均衡。也就是说，域名解析的结果为内部的负载均衡服务器 IP 地址**。



## ③ 反向代理负载均衡

**反向代理服务器（比如 Nginx）位于源服务器前面，用户的请求需要先经过反向代理服务器才能到达源服务器。**反向代理可以用来进行缓存、日志记录等，同时也可以用来做为负载均衡服务器。

在这种负载均衡转发方式下，客户端不直接请求源服务器，因此源服务器不需要外部 IP 地址，而反向代理需要配置内部和外部两套 IP 地址。

<img src="http://mdimg.sofice.top/202112301710372.png" style="zoom:50%;" />

优点：

- 与其它功能集成在一起，部署简单。

缺点：

- 所有请求和响应都需要经过反向代理服务器，它可能会成为性能瓶颈。



:question: 反向代理和其他的负载均衡技术区别

一般的负载均衡只是对请求数据包的转发和传递，服务器收到的还是来自客户端的真实用户的请求。而反向代理服务器收到客户端的请求后，会**重新向服务器发起请求**（Web服务器，文件服务器，视频服务器），与服务器交换数据，最后把数据返回给客户端。



## ④ IP 负载均衡

**在网络层通过修改请求目标地址进行负载均衡。**

<img src="http://mdimg.sofice.top/202112301710350.png" style="zoom:50%;" />

在操作系统内核进程获取网络数据包，根据负载均衡算法计算源服务器的 IP 地址，并修改请求数据包的目的 IP 地址，最后进行转发。

源服务器返回的响应也需要经过负载均衡服务器，通常是让负载均衡服务器同时作为集群的网关服务器来实现。

优点：

- 在内核进程中进行处理，性能比较高。

缺点：

- 和反向代理一样，所有的请求和响应都经过负载均衡服务器，会成为性能瓶颈。



## ⑤ 数据链路层负载均衡

**在数据链路层根据负载均衡算法计算源服务器的 MAC 地址，修改请求数据包的目的 MAC 地址，并进行转发。**

<img src="http://mdimg.sofice.top/202112301715859.png" style="zoom:50%;" />

通过配置源服务器的虚拟 IP 地址和负载均衡服务器的 IP 地址一致，从而不需要修改 IP 地址就可以进行转发。也正因为 IP 地址一样，所以源服务器的响应不需要转发回负载均衡服务器，可以直接转发给客户端，避免了负载均衡服务器的成为瓶颈。

这是一种三角传输模式，被称为直接路由。对于提供下载和视频服务的网站来说，直接路由避免了大量的网络传输数据经过负载均衡服务器。

这是目前大型网站使用最广负载均衡转发方式，在 Linux 平台可以使用的负载均衡服务器为 LVS（Linux Virtual Server）。

