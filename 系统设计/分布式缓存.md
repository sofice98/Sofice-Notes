# 分布式缓存设计的核心问题

Redis缓存的使用，极大的提升了应用程序的性能和效率，特别是数据查询方面。

但同时，它也带来了一些问题。其中，最要害的问题，就是数据的一致性问题，从严格意义上讲，这个问题无解。如果对数据的一致性要求很高，那么就不能使用缓存。



# 缓存预热

在请求数据前先加载到缓存系统中，以提高查询效率。一般有系统启动加载、定时加载等方式。



# 缓存更新

数据变化后将变化的数据更新到缓存中

- **定时更新：**定时将数据库数据更新到缓存中，适合需要缓存数据量不大的情况
- **过期更新：**定时更新过期的数据。
- **写请求更新：**有写请求时进行更新，适用于对缓存数据有强一致性的要求，即缓存的一致性，见下面详细说明。
- **读请求更新：**有读请求时，若缓存不存在或已过期，将数据库查询结果更新到缓存中，返回缓存中数据。



## 缓存一致性（写请求更新）

“数据一致”一般指的是：缓存中有数据，缓存的数据值=数据库中的值。



根据是否接收写请求，可以把缓存分成：

- **只读缓存：**只在缓存进行数据查找，即使用“更新数据库+删除缓存”策略。

- **读写缓存：**需要在缓存中对数据进行增删改查，即使用“更新数据库+更新缓存”策略。

 

### **只读缓存（删除缓存）**

- **新增数据时** ，写入数据库；访问数据时，缓存缺失，查数据库，更新缓存（始终是处于“数据一致”的状态，不会发生数据不一致性问题）

- **更新（修改/删除）数据时**，会有个时序问题：更新数据库与删除缓存的顺序（这个过程会发生数据不一致性问题）

<img src="http://mdimg.sofice.top/202201251323170.webp" alt="图片" style="zoom: 67%;" />

在更新数据的过程中，可能会有如下问题：

- 无并发请求下，其中一个操作失败的情况。因此要保证两个步骤都能成功执行。

- 并发请求下，其他线程可能会读到旧值。因此要避免或消除其他线程的影响。



接下来，我们针对有/无并发场景，进行分析并使用不同的策略。

**一、无并发情况**

无并发请求下，在更新数据库和删除缓存值的过程中，因为操作被拆分成两步，那么就很有可能存在“步骤1成功，步骤2失败” 的情况发生（由于单线程中步骤1和步骤2是串行执行的，不太可能会发生 “步骤2成功，步骤1失败” 的情况）。

**① 先删除缓存，再更新数据库**

<img src="http://mdimg.sofice.top/202201251323405.webp" alt="图片" style="zoom: 67%;" />

**② 先更新数据库，再删除缓存**



<img src="http://mdimg.sofice.top/202201251323248.webp" alt="图片" style="zoom:67%;" />



![图片](http://mdimg.sofice.top/202201251323184.webp)



**解决策略：**

**① 消息队列+异步重试**

无论使用哪一种执行时序，可以在执行步骤1时，将步骤2的请求写入消息队列，当步骤2失败时，就可以使用重试策略，对失败操作进行“补偿”。

具体步骤如下：

- 把要删除的缓存值或者是要更新的数据库值暂存到消息队列中（例如使用Kafka消息队列）

- 当删除缓存值或者是更新数据库值成功时，把这些值从消息队列中去除，以免重复操作。

- 当删除缓存值或者是更新数据库值失败时，执行失败策略，重试服务从消息队列中重新读取这些值，然后再次进行删除或更新。

- 删除或者更新失败时，需要再次进行重试，重试超过的一定次数。向业务层发送报错信息。

<img src="http://mdimg.sofice.top/202201251323469.webp" alt="图片" style="zoom: 67%;" />



**② 订阅Binlog变更日志**

- 创建更新缓存服务，接收数据变更的MQ消息，然后消费消息，更新/删除Redis中的缓存数据。

- 使用Binlog实时更新/删除Redis缓存。利用Canal，即将负责更新缓存的服务伪装成一个MySQL的从节点，从MySQL接收Binlog，解析Binlog之后，得到实时的数据变更信息，然后根据变更信息去更新/删除Redis缓存。

- MQ+Canal策略，将Canal Server接收到的Binlog数据直接投递到MQ进行解耦，使用MQ异步消费Binlog日志，以此进行数据同步。

不管用MQ/Canal或者MQ+Canal的策略来异步更新缓存，对整个更新服务的数据可靠性和实时性要求都比较高，如果产生数据丢失或者更新延时情况，会造成MySQL和Redis中的数据不一致。因此，使用这种策略时，需要考虑出现不同步问题时的降级或补偿方案。



**二、高并发情况**

使用以上策略后，可以保证在单线程/无并发场景下的数据一致性。但是，在高并发场景下，由于数据库层面的读写并发，会引发的数据库与缓存数据不一致的问题（本质是后发生的读请求先返回了）



**① 先删除缓存，再更新数据库**

其本质就是，本应后发生的“B线程-读请求”先于“A线程-写请求”执行并返回了。

| 时间 | 线程A             | 线程B                                 | 问题                     |
| ---- | ----------------- | ------------------------------------- | ------------------------ |
| T1   | 删除X的缓存       |                                       |                          |
| T2   |                   | 1.读取缓存数据X，缓存缺失，从数据库读 | 线程B读到旧值            |
| T3   |                   | 2.将数据X的值写入缓存                 | 导致其它线程读到旧值     |
| T4   | 更新数据库中X的值 |                                       | 缓存是旧值，数据库是新值 |

或者

| 时间 | 线程A             | 线程B                                 | 问题                     |
| ---- | ----------------- | ------------------------------------- | ------------------------ |
| T1   | 删除X的缓存       |                                       |                          |
| T2   |                   | 1.读取缓存数据X，缓存缺失，从数据库读 | 线程B读到旧值            |
| T3   | 更新数据库中X的值 |                                       |                          |
| T4   |                   | 2.将数据X的值写入缓存                 | 缓存是旧值，数据库是新值 |

**② 先更新数据库，再删除缓存**

本应后发生的“B线程-读请求”先于“A线程-删除缓存”执行并返回了。

![图片](http://mdimg.sofice.top/202201251323681.webp)

或者，“读写分离+主从库延迟”也会导致不一致：

![图片](http://mdimg.sofice.top/202201251323807.webp)



**先删除缓存，再更新数据库的解决策略：**

**① 设置缓存过期时间+延时双删**

通过**设置缓存过期时间**，若发生上述淘汰缓存失败的情况，则在缓存过期后，读请求仍然可以从DB中读取最新数据并更新缓存，可减小数据不一致的影响范围。虽然在一定时间范围内数据有差异，但可以保证数据的最终一致性。

此外，还可以通过**延时双删**进行保障：在线程A更新完数据库值以后，让它先sleep一小段时间，确保线程B能够先从数据库读取数据，再把缺失的数据写入缓存，然后，线程A再进行删除。后续其它线程读取数据时，发现缓存缺失，会从数据库中读取最新值。

```
redis.delKey(X)
db.update(X)
Thread.sleep(N)
redis.delKey(X)
```

sleep时间：在业务程序运行的时候，统计下线程读数据和写缓存的操作时间，以此为基础来进行估算。

![图片](http://mdimg.sofice.top/202201251323766.webp)

注意：如果难以接受sleep这种写法，可以使用延时队列进行替代。

先删除缓存值再更新数据库，有可能导致请求因缓存缺失而访问数据库，给数据库带来压力，也就是缓存穿透的问题。针对缓存穿透问题，可以用缓存空结果、布隆过滤器进行解决。





**先更新数据库，再删除缓存的解决方案：**

**① 延迟消息**

凭借经验发送「延迟消息」到队列中，延迟删除缓存，同时也要控制主从库延迟，尽可能降低不一致发生的概率。

**② 订阅binlog，异步删除**

通过数据库的binlog来异步淘汰key，利用工具（canal）将binlog日志采集发送到MQ中，然后通过ACK机制确认处理删除缓存。

**③ 删除消息写入数据库**

通过比对数据库中的数据，进行删除确认先更新数据库再删除缓存，有可能导致请求因缓存缺失而访问数据库，给数据库带来压力，也就是缓存穿透的问题。针对缓存穿透问题，可以用缓存空结果、布隆过滤器进行解决。

**④ 加锁**

更新数据时，加写锁；查询数据时，加读锁。

![图片](http://mdimg.sofice.top/202201251323891.webp)

建议：

优先使用“先更新数据库再删除缓存”的执行时序，原因主要有两个：

- 先删除缓存值再更新数据库，有可能导致请求因缓存缺失而访问数据库，给数据库带来压力。

- 业务应用中读取数据库和写缓存的时间有时不好估算，进而导致延迟双删中的sleep时间不好设置。



### 读写缓存（更新缓存）

**读写缓存**：增删改在缓存中进行，并采取相应的回写策略，同步数据到数据库中。

**同步直写**：使用事务，保证缓存和数据更新的原子性，并进行失败重试（如果Redis本身出现故障，会降低服务的性能和可用性）

**异步回写**：写缓存时不同步写数据库，等到数据从缓存中淘汰时，再写回数据库（没写回数据库前，缓存发生故障，会造成数据丢失）

该策略在秒杀场中有见到过，业务层直接对缓存中的秒杀商品库存信息进行操作，一段时间后再回写数据库。

**一致性**：同步直写>异步回写，因此，对于读写缓存，要保持数据强一致性的主要思路是：利用同步直写，同步直写也存在两个操作的时序问题：更新数据库和更新缓存。

- ##### 无并发情况



![图片](http://mdimg.sofice.top/202201251323067.webp)





- ##### 高并发情况



有四种场景会造成数据不一致：



![图片](http://mdimg.sofice.top/202201251323105.webp)



针对场景1和2的解决方案是：保存请求对缓存的读取记录，延时消息比较，发现不一致后，做业务补偿 针对场景3和4的解决方案是：对于写请求，需要配合分布式锁使用。写请求进来时，针对同一个资源的修改操作，先加分布式锁，保证同一时间只有一个线程去更新数据库和缓存；没有拿到锁的线程把操作放入到队列中，延时处理。用这种方式保证多个线程操作同一资源的顺序性，以此保证一致性。



![图片](http://mdimg.sofice.top/202201251323263.webp)



其中，分布式锁的实现可以使用以下策略：



![图片](http://mdimg.sofice.top/202201251323329.webp)





### 强一致性策略

上述策略只能保证数据的最终一致性。要想做到强一致，最常见的方案是2PC、3PC、Paxos、Raft这类一致性协议，但它们的性能往往比较差，而且这些方案也比较复杂，还要考虑各种容错问题。如果业务层要求必须读取数据的强一致性，可以采取以下策略：

- 暂存并发读请求

  在更新数据库时，先在Redis缓存客户端暂存并发读请求，等数据库更新完、缓存值删除后，再读取数据，从而保证数据一致性。

- 串行化

  读写请求入队列，工作线程从队列中取任务来依次执行

  - 修改服务Service连接池，id取模选取服务连接，能够保证同一个数据的读写都落在同一个后端服务上。
  - 修改数据库DB连接池，id取模选取DB连接，能够保证同一个数据的读写在数据库层面是串行的。
  - 使用Redis分布式读写锁

  将淘汰缓存与更新库表放入同一把写锁中，与其它读请求互斥，防止其间产生旧数据。读写互斥、写写互斥、读读共享，可满足读多写少的场景数据一致，也保证了并发性。并根据逻辑平均运行时间、响应超时时间来确定过期时间。

```java
public void write() {    
    Lock writeLock = redis.getWriteLock(lockKey);    
    writeLock.lock();    
    try {        
    redis.delete(key);        
        db.update(record);    
    } finally {       
        writeLock.unlock();    
    }
}
public void read() {    
    if (caching) {        
        return;    
    }    
    // no cache    
    Lock readLock = redis.getReadLock(lockKey);    
    readLock.lock();    
    try {        
        record = db.get();    
    } finally {        
        readLock.unlock();    
    }    
    redis.set(key, record);
}
```



### 小结

![图片](http://mdimg.sofice.top/202201251323391.webp)

针对读写缓存时：同步直写，更新数据库+更新缓存

![图片](http://mdimg.sofice.top/202201251323516.webp)

针对只读缓存时：更新数据库+删除缓存



![图片](http://mdimg.sofice.top/202201251323678.webp)



较为通用的一致性策略拟定：

在并发场景下，使用“更新数据库+更新缓存”需要用分布式锁保证缓存和数据一致性，且可能存在“缓存资源浪费”和“机器性能浪费”的情况；一般推荐使用“更新数据库+删除缓存”的方案。如果根据需要，热点数据较多，可以使用“更新数据库+更新缓存”策略。

在“更新数据库+删除缓存”的方案中，推荐使用推荐用“先更新数据库，再删除缓存”策略，因为先删除缓存可能会导致大量请求落到数据库，而且延迟双删的时间很难评估。

在“先更新数据库，再删除缓存”策略中，可以使用“消息队列+重试机制”的方案保证缓存的删除。并通过“订阅binlog”进行缓存比对，加上一层保障。

此外，需要通过初始化缓存预热、多数据源触发、延迟消息比对等策略进行辅助和补偿。【多种数据更新触发源：定时任务扫描，业务系统MQ、binlog变更MQ，相互之间作为互补来保证数据不会漏更新】



**三、数据不一致性需注意其他问题**

**(一) k-v大小的合理设置**

Redis key大小设计：由于网络的一次传输MTU最大为1500字节，所以为了保证高效的性能，建议单个k-v大小不超过1KB，一次网络传输就能完成，避免多次网络交互；k-v是越小性能越好

Redis热key：当业务遇到单个读热key，通过增加副本来提高读能力或是用hashtag把key存多份在多个分片中。

当业务遇到单个写热key，需业务拆分这个key的功能，属于设计不合理-当业务遇到热分片，即多个热key在同一个分片上导致单分片cpu高，可通过hashtag方式打散。



**（二）避免其他问题导致缓存服务器崩溃，进而简直导致数据一致性策略失效缓存穿透、缓存击穿、缓存雪崩、机器故障等问题**

![图片](http://mdimg.sofice.top/202201251323691.webp)



**（三）方案选定的思路**

- 确定缓存类型（读写/只读）

- 确定一致性级别

- 确定同步/异步方式

- 选定缓存流程

- 补充细节





# 缓存淘汰策略

缓存过多时需要使用淘汰算法淘汰一些数据。

- FIFO：按存储时间，先存先淘汰
- LRU：按最近被使用的时间，最近最少使用
- LFU：一段时间内，使用次数最少的（最不经常使用）



# 缓存穿透（查不到）

当用户很多的时候，缓存都没有命中，于是都去请求了持久层数据库。这会给持久层数据库造成很大的压力，这时候就出现了缓存穿透。



**解决方案**

**① 布隆过滤器**

布隆过滤器是一种数据结构，对所有可能查询的参数以 hash 形式存储，在控制层先进行校验，**一个一定不存在的数据会被布隆过滤器丢弃**，从而避免了对底层存储系统的查询压力

![](http://mdimg.sofice.top/202201251056110.png)

**② 缓存空对象（cache null）**

当存储层不命中后，即使返回的空对象也将其缓存起来，同时会设置一个过期时间（过期时间会很短），之后再访问这个数据将会从缓存中获取，保护了后端数据源

![](http://mdimg.sofice.top/202201251056046.png)

但是这种方法会存在两个问题：

- 如果空值能够被缓存起来，这就意味着缓存需要更多的空间存储更多的键，因为这当中可能会有很多的空值的键；

- 即使对空值设置了过期时间，还是会存在缓存层和存储层的数据会有一段时间窗口的不一致，这对于需要保持一致性的业务会有影响。



# 缓存击穿（查的太多）

缓存击穿，是指一个 key 非常热点，在不停的扛着大并发，大并发集中。对这一个点进行访问，当这个key在失效的瞬间，持续的大并发就穿破缓存，直接请求数据库，导使数据库瞬间压力过大。



**解决方案**

**① 设置热点数据永不过期**

从缓存层面来看，不设置过期时间，就不会出现热点 key 过期后产生的问题。

**② 加互斥锁**

使用分布式锁，保证对于每个 key 同时只有一个线程去查询后端服务，其他线程没有获得分布式锁的权限，因此只需要等待即可。这种方式将高并发的压力转移到了分布式锁，因此对分布式锁的考验很大。



# 缓存雪崩

缓存雪崩，是指在某一个时间段，缓存集中过期失效，Redis 宕机。

其实缓存集中过期，倒不是非常致命，比较致命的缓存雪崩，是缓存服务器某个节点宕机或断网。因为自然形成的缓存雪崩，一定是在某个时间段集中创建缓存，这个时候，数据库也是可以顶住压力的。无非就是对数据库产生周期性的压力而已。而缓存服务节点的宕机，对数据库服务器造成的压力是不可预知的，很有可能瞬间就把数据库压垮。



**解决方案**

**① 请求加锁**

对于并发量不是很多的应用，在缓存失效后，通过加锁或者队列来控制读数据库写缓存的线程数量。比如对某个 key 只允许一个线程查询数据和写缓存，其他线程等待。

**② 失效更新**

为每一个缓存数据增加过期标记，失效则更新缓存。

**③ 设置不同失效时间**

在即将发生大并发访问前定时缓存预热，设置不同的过期时间，让缓存失效的时间点尽量均匀。



# 缓存降级

访问量剧增时，减少或关闭非核心业务对资源的使用，优先保障核心业务的运行。

- 写降级：写请求增多时，可以只进行Cache的更新，然后将数据异步更新到数据库中，保证最终一致性即可。即将写请求从数据库降级为缓存。
- 读降级：当数据库负载过高或故障时，可以只对缓存读取，即将读请求从数据库降级为缓存。适用于对数据实时性要求不高的场景，保障了故障时用户依然能够访问到数据，只是相对有延迟。